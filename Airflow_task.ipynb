{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3557430d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\home/airflow/dags/Spam Detection Collection/constants.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m module\n\u001b[1;32m---> 41\u001b[0m constants \u001b[38;5;241m=\u001b[39m  \u001b[43mmodule_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstants\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/airflow/dags/Spam Detection Collection/constants.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_inference_data\u001b[39m():\n\u001b[0;32m     44\u001b[0m     encodings_to_try \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin-1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO-8859-1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcp1252\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[3], line 38\u001b[0m, in \u001b[0;36mmodule_from_file\u001b[1;34m(module_name, file_path)\u001b[0m\n\u001b[0;32m     36\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, file_path) \n\u001b[0;32m     37\u001b[0m module\u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mmodule_from_spec(spec)\n\u001b[1;32m---> 38\u001b[0m \u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1016\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1073\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\home/airflow/dags/Spam Detection Collection/constants.py'"
     ]
    }
   ],
   "source": [
    "#Utils.py contains all utility functions used during the inference process\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, f1_score, average_precision_score, recall_score,classification_report,confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import joblib\n",
    "import importlib.util\n",
    "\n",
    "DATA_DIR = r\"C:\\Users\\K\\Downloads\\Great Learning\\NLP\\Project\\Spam Detection Collection\\spam.csv\"\n",
    "MODEL_DIR = r\"C:\\Users\\K\\Downloads\\Great Learning\\NLP\\Project\\spam_detection_model.pkl\"\n",
    "\n",
    "\n",
    "def module_from_file(module_name, file_path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_path) \n",
    "    module= importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "constants =  module_from_file(\"constants\",\"/home/airflow/dags/Spam Detection Collection/constants.py\")\n",
    "\n",
    "def get_inference_data():\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'ISO-8859-1', 'cp1252']\n",
    "\n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(r\"C:\\Users\\K\\Downloads\\Great Learning\\NLP\\Project\\Spam Detection Collection\\spam.csv\", encoding=encoding)\n",
    "            print(f\"Successfully loaded using encoding: {encoding}\")\n",
    "            break\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to load using encoding: {encoding}\")\n",
    "    df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)\n",
    "    df = df.drop_duplicates(keep='first')\n",
    "    df.rename(columns = {'v1':'label','v2':'text'},inplace=True)\n",
    "    df.to_csv(f\"{DATA_DIR}/spam_detect_inference.csv\", index = False)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    global stop_words\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    text = ' '.join([word for word in tokens if word.lower() not in stop_words])\n",
    "    df['text'] = df['text'].apply(preprocess_text)\n",
    "    df.to_csv(f\"{DATA_DIR}/spam_detect_preprocess_text.csv\", index = False)\n",
    "\n",
    "def predict_data():\n",
    "    df = pd.read_csv(f\"{DATA_DIR}/spam_detect_preprocess_text.csv\")\n",
    "    model = joblib.load(f\"{MODEL_DIR}/spam_detect_model.joblib\") \n",
    "    predictions = model.predict(df)\n",
    "    prediction_df = pd.DataFrame (predictions)\n",
    "    prediction_df.to_csv(f\"{DATA_DIR}/spam_detect.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ae86b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
